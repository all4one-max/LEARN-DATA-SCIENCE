{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTING THE NECESSARY MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd,numpy as np,math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING THE IRIS DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(iris.data)\n",
    "df.columns = [\"sl\", \"sw\", 'pl', 'pw']\n",
    "flower_type = ['setosa', 'versicolor', 'virginica']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONVERTING THE CONTINUOUS NATURE OF IRIS DATASET TO A MORE CONVENIENT DISCRETE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Decision Trees\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import *\n",
    "from sklearn import datasets\n",
    "\n",
    "def label(val, *boundaries):\n",
    "    if (val < boundaries[0]):\n",
    "        return 'a'\n",
    "    elif (val < boundaries[1]):\n",
    "        return 'b'\n",
    "    elif (val < boundaries[2]):\n",
    "        return 'c'\n",
    "    else:\n",
    "        return 'd'\n",
    "\n",
    "def toLabel(df, old_feature_name):\n",
    "    second = df[old_feature_name].mean()\n",
    "    minimum = df[old_feature_name].min()\n",
    "    first = (minimum + second)/2\n",
    "    maximum = df[old_feature_name].max()\n",
    "    third = (maximum + second)/2\n",
    "    return df[old_feature_name].apply(label, args= (first, second, third))\n",
    "\n",
    "\n",
    "df = datasets.load_iris()\n",
    "X = pd.DataFrame(df.data)\n",
    "Y = pd.DataFrame(df.target)\n",
    "X.columns = ['sl','sw','pl','pw']\n",
    "\n",
    "X['sl_class'] = toLabel(X,'sl')\n",
    "X['sw_class'] = toLabel(X,'sw')\n",
    "X['pl_class'] = toLabel(X,'pl')\n",
    "X['pw_class'] = toLabel(X,'pw')\n",
    "\n",
    "#THIS PART WAS TO CONVERT THE GIVEN IRIS DATASET WHICH IS CONTINUOUS INTO A DISCRETE DATASET\n",
    "\n",
    "X.drop(columns=['sl','sw','pl','pw'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 1 - PRINTING THE DECISION TREE AS SPECIFIED IN THE QUESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 0\n",
      "Count of setosa 50\n",
      "Count of versicolor 50\n",
      "Count of virginica 50\n",
      "Splitting on feature  pw_class with Gain Ratio 0.6996382036222092\n",
      "\n",
      "Level 1\n",
      "Count of setosa 0\n",
      "Count of versicolor 0\n",
      "Count of virginica 34\n",
      "Reached leaf Node\n",
      "\n",
      "Level 1\n",
      "Count of setosa 0\n",
      "Count of versicolor 10\n",
      "Count of virginica 0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 1\n",
      "Count of setosa 50\n",
      "Count of versicolor 0\n",
      "Count of virginica 0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 1\n",
      "Count of setosa 0\n",
      "Count of versicolor 40\n",
      "Count of virginica 16\n",
      "Splitting on feature  pl_class with Gain Ratio 0.43340994956210654\n",
      "\n",
      "Level 2\n",
      "Count of setosa 0\n",
      "Count of versicolor 1\n",
      "Count of virginica 0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 2\n",
      "Count of setosa 0\n",
      "Count of versicolor 39\n",
      "Count of virginica 8\n",
      "Splitting on feature  sl_class with Gain Ratio 0.12674503775809323\n",
      "\n",
      "Level 3\n",
      "Count of setosa 0\n",
      "Count of versicolor 0\n",
      "Count of virginica 1\n",
      "Reached leaf Node\n",
      "\n",
      "Level 3\n",
      "Count of setosa 0\n",
      "Count of versicolor 14\n",
      "Count of virginica 0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 3\n",
      "Count of setosa 0\n",
      "Count of versicolor 23\n",
      "Count of virginica 7\n",
      "Splitting on feature  sw_class with Gain Ratio 0.07092036405148884\n",
      "\n",
      "Level 4\n",
      "Count of setosa 0\n",
      "Count of versicolor 3\n",
      "Count of virginica 1\n",
      "Splitting not possible as no features are left\n",
      "\n",
      "Level 4\n",
      "Count of setosa 0\n",
      "Count of versicolor 14\n",
      "Count of virginica 6\n",
      "Splitting not possible as no features are left\n",
      "\n",
      "Level 4\n",
      "Count of setosa 0\n",
      "Count of versicolor 6\n",
      "Count of virginica 0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 3\n",
      "Count of setosa 0\n",
      "Count of versicolor 2\n",
      "Count of virginica 0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 2\n",
      "Count of setosa 0\n",
      "Count of versicolor 0\n",
      "Count of virginica 8\n",
      "Reached leaf Node\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def entropy(Y): # THIS FUCTION WILL CALCULATE ENTROPY OVER THE GIVEN Y WHICH IS SPECIFIED OVER A PARTICULAR LABEL\n",
    "                # OF A GIVEN FEATURE\n",
    "    entrpy = 0\n",
    "    idx = Y.value_counts().index\n",
    "    val = Y.value_counts().values\n",
    "    tot = len(Y)\n",
    "    for i in range(len(idx)):\n",
    "        entrpy += -1*(val[i]/tot)*math.log(val[i]/tot,10)\n",
    "    return entrpy\n",
    "    \n",
    "def get_gain_ratio(X,Y,selected_feature): # THIS FUNCTION WILL CALCULATE THE GAIN RATIO OVER THE SPECIFIED FEATURE\n",
    "    INFOn = entropy(Y)\n",
    "    \n",
    "    INFOf = 0\n",
    "    D = len(Y)\n",
    "    D_idx = X[selected_feature].value_counts().index\n",
    "    D_val = X[selected_feature].value_counts().values    \n",
    "    for i in range(len(set(X[selected_feature]))): # FINDING THE WEIGHTED ENTROPY OF DIFFERET LABELS IN THE FEATURE\n",
    "        INFOf += (D_val[i]/D)*entropy(Y[X[selected_feature]==D_idx[i]])  \n",
    "    \n",
    "    split_info = 0\n",
    "    for i in range(len(set(X[selected_feature]))):\n",
    "        split_info += -(D_val[i]/D)*log(D_val[i]/D,10)\n",
    "    \n",
    "    return (INFOn-INFOf)/split_info  \n",
    "\n",
    "def count(Y): # THIS FUNCTION WILL COUNT THE NUMBER OF DIFFERENT FLOWER TYPES PRESENT IN Y\n",
    "    count_0 = Y[Y==0].count()\n",
    "    count_1 = Y[Y==1].count()\n",
    "    count_2 = Y[Y==2].count()\n",
    "    return count_0, count_1, count_2    \n",
    "\n",
    "def Dtree(X,Y,features,level):\n",
    "    \n",
    "    if len(set(Y))==1: # HANDLING THE CASE IN WHICH Y HAS A SINGLE FLOWER TYPE, HENCE A PURE NODE \n",
    "        print(\"Level\",level)\n",
    "        count_0, count_1, count_2 = count(Y)\n",
    "        print(\"Count of\",flower_type[0],count_0)\n",
    "        print(\"Count of\",flower_type[1],count_1)\n",
    "        print(\"Count of\",flower_type[2],count_2)\n",
    "        print(\"Reached leaf Node\")\n",
    "        print()\n",
    "        return\n",
    "    \n",
    "    if len(features)==0: # HANDLING THE CASES WHERE WE HAVE NO FEATURE TO SPLIT UPON\n",
    "        print(\"Level\",level)\n",
    "        count_0, count_1, count_2 = count(Y)\n",
    "        print(\"Count of\",flower_type[0],count_0)\n",
    "        print(\"Count of\",flower_type[1],count_1)\n",
    "        print(\"Count of\",flower_type[2],count_2)\n",
    "        print(\"Splitting not possible as no features are left\")\n",
    "        print()\n",
    "        return\n",
    "    \n",
    "    max_gain_ratio = 0    \n",
    "    for f in features:\n",
    "        gain_ratio = get_gain_ratio(X,Y,f)\n",
    "        if gain_ratio > max_gain_ratio:\n",
    "            max_gain_ratio = gain_ratio\n",
    "            final_feature = f\n",
    "    \n",
    "    print(\"Level\",level)\n",
    "    count_0, count_1, count_2 = count(Y)\n",
    "    print(\"Count of\",flower_type[0],count_0)\n",
    "    print(\"Count of\",flower_type[1],count_1)\n",
    "    print(\"Count of\",flower_type[2],count_2)\n",
    "    print(\"Splitting on feature \",final_feature,'with Gain Ratio',max_gain_ratio)\n",
    "    print()\n",
    "    \n",
    "    unique_val = set(X[final_feature])\n",
    "    features.remove(final_feature) # removing the selected feature\n",
    "    \n",
    "    for j in unique_val: # HERE WE WILL SPLIT OUR DATA OVER THE LABEL OF OUR FINAL FEATURE AND RECURSIVELY CALL\n",
    "                         # ON THE SPLITS\n",
    "        X_split = X[X[final_feature]==j]\n",
    "        Y_split = Y[X[final_feature]==j]        \n",
    "        Dtree(X_split,Y_split,features,level+1)     \n",
    "    return\n",
    "\n",
    "Dtree(X,Y[0],['sl_class','sw_class','pl_class','pw_class'],0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 2 - ACTUALLY IMPLEMENTING THE DECISION TREE USING OOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "    def __init__(self):\n",
    "        \"\"\"\" Init Block : \n",
    "            __init__() : Initializes the tree node      \n",
    "        \"\"\"        \n",
    "        self.feature_to_split = [False,-1] # initially i am initializing as no split has been done        \n",
    "        self.children = list() # this will store the child nodes\n",
    "        self.current_output = -1 # this will store current prediction\n",
    "        self.level = -1 # defining the level of a node\n",
    "        self.count_satosa = -1 \n",
    "        self.count_versicolor = -1\n",
    "        self.count_virginica = -1\n",
    "        self.reached_leaf = False # whether i have reached a pure node or not      \n",
    "        self.gain_ratio = -1\n",
    "        return\n",
    "                \n",
    "    def add_child(self,child):\n",
    "        \"\"\"\" Function : \n",
    "            add_child() : Adds a child node to the Tree\n",
    "        Parameters :\n",
    "            child        : Reference of child node   \n",
    "        \"\"\"\n",
    "        self.children.append(child)\n",
    "        return\n",
    "        \n",
    "    def print_details(self):\n",
    "        print(\"Level\",self.level)\n",
    "        print(\"Count of satosa\",self.count_satosa)\n",
    "        print(\"Count of versicolor\",self.count_versicolor)\n",
    "        print(\"Count of virginica\",self.count_virginica)\n",
    "        if self.reached_leaf == True:\n",
    "            print(\"Reached Pure Node\")\n",
    "        else:\n",
    "            if self.feature_to_split[0] == False:\n",
    "                print(\"No feature left to split upon\")\n",
    "            else:\n",
    "                print(\"Splitting on feature \",self.feature_to_split[1],'with Gain Ratio',self.gain_ratio)\n",
    "        print(\"Current Prediction is\",self.current_output)\n",
    "        print()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def entropy(Y): # THIS FUCTION WILL CALCULATE ENTROPY OVER THE GIVEN Y WHICH IS SPECIFIED OVER A PARTICULAR LABEL\n",
    "                # OF A GIVEN FEATURE\n",
    "    entrpy = 0\n",
    "    idx = Y.value_counts().index\n",
    "    val = Y.value_counts().values\n",
    "    tot = len(Y)\n",
    "    for i in range(len(idx)):\n",
    "        entrpy += -1*(val[i]/tot)*math.log(val[i]/tot,10)\n",
    "    return entrpy\n",
    "    \n",
    "def get_gain_ratio(X,Y,selected_feature): # THIS FUNCTION WILL CALCULATE THE GAIN RATIO OVER THE SPECIFIED FEATURE\n",
    "    INFOn = entropy(Y)\n",
    "    \n",
    "    INFOf = 0\n",
    "    D = len(Y)\n",
    "    D_idx = X[selected_feature].value_counts().index\n",
    "    D_val = X[selected_feature].value_counts().values    \n",
    "    for i in range(len(set(X[selected_feature]))): # FINDING THE WEIGHTED ENTROPY OF DIFFERET LABELS IN THE FEATURE\n",
    "        INFOf += (D_val[i]/D)*entropy(Y[X[selected_feature]==D_idx[i]])  \n",
    "    \n",
    "    split_info = 0\n",
    "    for i in range(len(set(X[selected_feature]))):\n",
    "        split_info += -(D_val[i]/D)*log(D_val[i]/D,10)\n",
    "    \n",
    "    return (INFOn-INFOf)/split_info  \n",
    "\n",
    "def count(Y): # THIS FUNCTION WILL COUNT THE NUMBER OF DIFFERENT FLOWER TYPES PRESENT IN Y\n",
    "    count_0 = Y[Y==0].count()\n",
    "    count_1 = Y[Y==1].count()\n",
    "    count_2 = Y[Y==2].count()\n",
    "    return count_0, count_1, count_2    \n",
    "\n",
    "def Dtree(X,Y,features,level):\n",
    "    \n",
    "    if len(set(Y))==1: # HANDLING THE CASE IN WHICH Y HAS A SINGLE FLOWER TYPE, HENCE A PURE NODE \n",
    "        node = TreeNode() # MAKING A TREE NODE\n",
    "        node.level = level\n",
    "        node.reached_leaf = True\n",
    "        count_0, count_1, count_2 = count(Y)  \n",
    "        node.count_satosa = count_0 \n",
    "        node.count_versicolor = count_1\n",
    "        node.count_virginica = count_2\n",
    "        cnt = [ [count_0,flower_type[0]], [count_1,flower_type[1]], [count_2,flower_type[2]] ]\n",
    "        cnt.sort(key=lambda x:x[0],reverse = True)\n",
    "        node.current_output = cnt[0][1]\n",
    "        return node\n",
    "    \n",
    "    if len(features)==0: # HANDLING THE CASES WHERE WE HAVE NO FEATURE TO SPLIT UPON\n",
    "        node = TreeNode() # MAKING A TREE NODE\n",
    "        node.level = level\n",
    "        count_0, count_1, count_2 = count(Y)   \n",
    "        node.count_satosa = count_0 \n",
    "        node.count_versicolor = count_1\n",
    "        node.count_virginica = count_2\n",
    "        cnt = [ [count_0,flower_type[0]], [count_1,flower_type[1]], [count_2,flower_type[2]] ]\n",
    "        cnt.sort(key=lambda x:x[0],reverse = True)\n",
    "        node.current_output = cnt[0][1]\n",
    "        return node\n",
    "    \n",
    "    max_gain_ratio = 0    \n",
    "    for f in features:\n",
    "        gain_ratio = get_gain_ratio(X,Y,f)\n",
    "        if gain_ratio > max_gain_ratio:\n",
    "            max_gain_ratio = gain_ratio\n",
    "            final_feature = f\n",
    "    \n",
    "    node = TreeNode() # MAKING A TREE NODE\n",
    "    node.level = level\n",
    "    count_0, count_1, count_2 = count(Y)\n",
    "    node.count_satosa = count_0 \n",
    "    node.count_versicolor = count_1\n",
    "    node.count_virginica = count_2\n",
    "    cnt = [ [count_0,flower_type[0]], [count_1,flower_type[1]], [count_2,flower_type[2]] ]\n",
    "    cnt.sort(key=lambda x:x[0],reverse = True)\n",
    "    node.current_output = cnt[0][1]\n",
    "    node.feature_to_split= [True,final_feature]\n",
    "    node.gain_ratio = max_gain_ratio\n",
    "    \n",
    "    unique_val = set(X[final_feature])\n",
    "    features.remove(final_feature) # removing the selected feature\n",
    "    \n",
    "    for j in unique_val: # HERE WE WILL SPLIT OUR DATA OVER THE LABEL OF OUR FINAL FEATURE AND RECURSIVELY CALL\n",
    "                         # ON THE SPLITS\n",
    "        X_split = X[X[final_feature]==j]\n",
    "        Y_split = Y[X[final_feature]==j]        \n",
    "        child_node = Dtree(X_split,Y_split,features,level+1)  \n",
    "        node.add_child(child_node)\n",
    "    return node\n",
    "\n",
    "root = Dtree(X,Y[0],['sl_class','sw_class','pl_class','pw_class'],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 0\n",
      "Count of satosa 50\n",
      "Count of versicolor 50\n",
      "Count of virginica 50\n",
      "Splitting on feature  pw_class with Gain Ratio 0.6996382036222092\n",
      "Current Prediction is setosa\n",
      "\n",
      "Level 1\n",
      "Count of satosa 0\n",
      "Count of versicolor 0\n",
      "Count of virginica 34\n",
      "Reached Pure Node\n",
      "Current Prediction is virginica\n",
      "\n",
      "Level 1\n",
      "Count of satosa 0\n",
      "Count of versicolor 10\n",
      "Count of virginica 0\n",
      "Reached Pure Node\n",
      "Current Prediction is versicolor\n",
      "\n",
      "Level 1\n",
      "Count of satosa 50\n",
      "Count of versicolor 0\n",
      "Count of virginica 0\n",
      "Reached Pure Node\n",
      "Current Prediction is setosa\n",
      "\n",
      "Level 1\n",
      "Count of satosa 0\n",
      "Count of versicolor 40\n",
      "Count of virginica 16\n",
      "Splitting on feature  pl_class with Gain Ratio 0.43340994956210654\n",
      "Current Prediction is versicolor\n",
      "\n",
      "Level 2\n",
      "Count of satosa 0\n",
      "Count of versicolor 1\n",
      "Count of virginica 0\n",
      "Reached Pure Node\n",
      "Current Prediction is versicolor\n",
      "\n",
      "Level 2\n",
      "Count of satosa 0\n",
      "Count of versicolor 39\n",
      "Count of virginica 8\n",
      "Splitting on feature  sl_class with Gain Ratio 0.12674503775809323\n",
      "Current Prediction is versicolor\n",
      "\n",
      "Level 3\n",
      "Count of satosa 0\n",
      "Count of versicolor 0\n",
      "Count of virginica 1\n",
      "Reached Pure Node\n",
      "Current Prediction is virginica\n",
      "\n",
      "Level 3\n",
      "Count of satosa 0\n",
      "Count of versicolor 14\n",
      "Count of virginica 0\n",
      "Reached Pure Node\n",
      "Current Prediction is versicolor\n",
      "\n",
      "Level 3\n",
      "Count of satosa 0\n",
      "Count of versicolor 23\n",
      "Count of virginica 7\n",
      "Splitting on feature  sw_class with Gain Ratio 0.07092036405148884\n",
      "Current Prediction is versicolor\n",
      "\n",
      "Level 4\n",
      "Count of satosa 0\n",
      "Count of versicolor 3\n",
      "Count of virginica 1\n",
      "No feature left to split upon\n",
      "Current Prediction is versicolor\n",
      "\n",
      "Level 4\n",
      "Count of satosa 0\n",
      "Count of versicolor 14\n",
      "Count of virginica 6\n",
      "No feature left to split upon\n",
      "Current Prediction is versicolor\n",
      "\n",
      "Level 4\n",
      "Count of satosa 0\n",
      "Count of versicolor 6\n",
      "Count of virginica 0\n",
      "Reached Pure Node\n",
      "Current Prediction is versicolor\n",
      "\n",
      "Level 3\n",
      "Count of satosa 0\n",
      "Count of versicolor 2\n",
      "Count of virginica 0\n",
      "Reached Pure Node\n",
      "Current Prediction is versicolor\n",
      "\n",
      "Level 2\n",
      "Count of satosa 0\n",
      "Count of versicolor 0\n",
      "Count of virginica 8\n",
      "Reached Pure Node\n",
      "Current Prediction is virginica\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def printDecisionTree(root): # now, i will print the tree \n",
    "    root.print_details()\n",
    "    \n",
    "    if len(root.children) == 0:\n",
    "        return\n",
    "    \n",
    "    for childs in root.children:\n",
    "        printDecisionTree(childs)\n",
    "        \n",
    "    return \n",
    "\n",
    "printDecisionTree(root)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
