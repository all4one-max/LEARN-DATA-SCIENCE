{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE: \n",
    "## PLEASE SEE THAT I HAVE ATTACHED THE mini_newsgroup FOLDER IN THE ZIP FILE ITSELF AND ALSO A TEXT FILE english.txt HAS BEEN ATTACHED IN THE ZIP FILE WHICH HAS BEEN USED IN THE PROJECT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTING THE NECESSARY MODULES FOR THE PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk,os,re,numpy as np\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import datasets\n",
    "stop_words = stopwords.words('english') # getting the list of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\jhasa\\\\Desktop\\\\mini_newsgroups\"\n",
    "folders = os.listdir(path)\n",
    "word_frequency = {}\n",
    "file = open(\"C:\\\\Users\\\\jhasa\\\\Desktop\\\\english.txt\", 'r') # this file contains some extra useless words \n",
    "line = file.read()\n",
    "useless_words = line.split(\"\\n\")\n",
    "useless_words.extend(stop_words)\n",
    "regex = r\"[A-z]+\" # this pattern will ensure that we have only words which contains alphabets only\n",
    "for folder in folders:\n",
    "    file = os.listdir(path+'\\\\'+folder) # fetching all the directories in the path\n",
    "    curr_path = path+'\\\\'+folder\n",
    "    for document in file:\n",
    "        with open(curr_path+\"\\\\\"+document,'r') as doc:\n",
    "            for line in doc:\n",
    "                stripped=re.split('\\W+',line) # splitting each line such that it will contain words only\n",
    "                for word in stripped:\n",
    "                    if word.strip().lower() not in useless_words and re.findall(regex,word.strip().lower())==[word.strip().lower()]:\n",
    "                        word_frequency[word.strip().lower()] = word_frequency.get(word.strip().lower(),0)+1\n",
    "                        # in this regex exp i am ensuring that none of the useless words gets counted and the word which\n",
    "                        # i count contains only alphabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequency=list(word_frequency.items())\n",
    "word_frequency.sort(key=lambda x : x[1],reverse=True)\n",
    "feature_set=list(map(lambda x:x[0],word_frequency[:2000])) # making a feature set of 2000 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now i will make my dataset\n",
    "path = \"C:\\\\Users\\\\jhasa\\\\Desktop\\\\mini_newsgroups\"\n",
    "folders = os.listdir(path)\n",
    "x = [] # this is will contain the data of all the documents in different folders\n",
    "y = [] # this will store the target data\n",
    "for folder in folders:\n",
    "    file = os.listdir(path+'\\\\'+folder)\n",
    "    curr_path = path+'\\\\'+folder\n",
    "    for document in file:\n",
    "        y.append(folder)\n",
    "        form_row = list(np.zeros(2000,dtype=int)) # here i will store the frequency of all the words of the feature set\n",
    "                                                  # that occur in this document \n",
    "        with open(curr_path+\"\\\\\"+document,'r') as doc:\n",
    "            all_doc_words = [] # i will store all the words of the document in this list\n",
    "            for line in doc:\n",
    "                words = re.split('\\W+',line) # splitting each line such that it will contain words only\n",
    "                words = [word.strip().lower() for word in words]\n",
    "                all_doc_words.extend(words)\n",
    "        all_doc_words = Counter(all_doc_words)\n",
    "        for i in range(2000):\n",
    "            if feature_set[i] in all_doc_words:\n",
    "                form_row[i]+=all_doc_words[feature_set[i]]\n",
    "        x.append(form_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # here i will split my data into training and testing\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USING INBUILT MULTI-NOMIAL NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB() # making the classifier object\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test) # predicting using the classifier object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLASSIFICATION REPORT OF x_train AND x_test USING THE INBUILT MULTINOMIAL NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.94      0.90      0.92        73\n",
      "           comp.graphics       0.87      0.93      0.90        74\n",
      " comp.os.ms-windows.misc       0.85      1.00      0.92        78\n",
      "comp.sys.ibm.pc.hardware       0.95      0.99      0.97        71\n",
      "   comp.sys.mac.hardware       0.93      0.96      0.95        74\n",
      "          comp.windows.x       1.00      0.65      0.79        66\n",
      "            misc.forsale       0.89      1.00      0.94        84\n",
      "               rec.autos       0.92      1.00      0.96        72\n",
      "         rec.motorcycles       0.97      0.99      0.98        78\n",
      "      rec.sport.baseball       1.00      0.97      0.99        72\n",
      "        rec.sport.hockey       0.99      1.00      0.99        80\n",
      "               sci.crypt       0.99      0.99      0.99        80\n",
      "         sci.electronics       1.00      0.78      0.88        74\n",
      "                 sci.med       1.00      0.99      0.99        74\n",
      "               sci.space       0.96      0.97      0.97        76\n",
      "  soc.religion.christian       1.00      0.99      0.99        75\n",
      "      talk.politics.guns       0.96      0.99      0.97        78\n",
      "   talk.politics.mideast       0.97      0.99      0.98        67\n",
      "      talk.politics.misc       0.94      0.93      0.94        73\n",
      "      talk.religion.misc       0.89      0.90      0.90        81\n",
      "\n",
      "                accuracy                           0.95      1500\n",
      "               macro avg       0.95      0.95      0.95      1500\n",
      "            weighted avg       0.95      0.95      0.95      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "y_train_pred=clf.predict(x_train)\n",
    "print(classification_report(y_train,y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.84      0.59      0.70        27\n",
      "           comp.graphics       0.66      0.73      0.69        26\n",
      " comp.os.ms-windows.misc       0.46      0.59      0.52        22\n",
      "comp.sys.ibm.pc.hardware       0.59      0.69      0.63        29\n",
      "   comp.sys.mac.hardware       0.76      0.73      0.75        26\n",
      "          comp.windows.x       0.92      0.35      0.51        34\n",
      "            misc.forsale       0.48      0.81      0.60        16\n",
      "               rec.autos       0.73      0.79      0.76        28\n",
      "         rec.motorcycles       0.76      1.00      0.86        22\n",
      "      rec.sport.baseball       0.82      0.96      0.89        28\n",
      "        rec.sport.hockey       0.94      0.80      0.86        20\n",
      "               sci.crypt       0.90      0.95      0.93        20\n",
      "         sci.electronics       0.88      0.54      0.67        26\n",
      "                 sci.med       0.92      0.85      0.88        26\n",
      "               sci.space       0.90      0.75      0.82        24\n",
      "  soc.religion.christian       0.89      1.00      0.94        25\n",
      "      talk.politics.guns       0.64      0.82      0.72        22\n",
      "   talk.politics.mideast       0.97      0.88      0.92        33\n",
      "      talk.politics.misc       0.66      0.70      0.68        27\n",
      "      talk.religion.misc       0.55      0.58      0.56        19\n",
      "\n",
      "                accuracy                           0.75       500\n",
      "               macro avg       0.76      0.76      0.74       500\n",
      "            weighted avg       0.78      0.75      0.75       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPLEMENTATION OF MULTINOMIAL NAIVE BYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# making numpy arrays\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit function\n",
    "def fit(x_train, y_train): \n",
    "    result = {} # declaration of the dictionary \n",
    "    result[\"total_doc\"] = len(y_train) # \"total_doc\" will store the number of documents we have\n",
    "    for current_class in set(y_train):\n",
    "        result[current_class] = {} # making another dictionary corresponding to each class\n",
    "        x_train_current = x_train[ y_train == current_class ]\n",
    "        y_train_current = y_train[ y_train == current_class ]\n",
    "        total_words = 0 # this will store the total number of words of this class\n",
    "        for i in range(len(feature_set)):\n",
    "            result[current_class][feature_set[i]] = (x_train_current[:,i]).sum() # here i stored the frequency of word\n",
    "                                                                                 # feature_set[i] in the given class\n",
    "            total_words += (x_train_current[:,i]).sum()\n",
    "        result[current_class][\"total_words\"] = total_words # storing the total number of words of the given class\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the probability of a test data point being a particular class\n",
    "def prob(dictionary, x, current_class):\n",
    "    class_prob = np.log(dictionary[current_class][\"total_words\"]) - np.log(dictionary[\"total_doc\"])\n",
    "    # in simple words this is P(y=current_class)\n",
    "    for i in range(len(feature_set)):\n",
    "        xi = x[i] \n",
    "        if xi == 0: # if the frequency of a given word of the feature in the test data point in 0 then would take\n",
    "                    # the current_prob as 0\n",
    "            current_prob = 0\n",
    "        else:\n",
    "            num = dictionary[current_class][feature_set[i]] + 1 # in simple words this is frequency of word feature_set[i]\n",
    "                                                                # of given class and '+1' is for lapalace correction\n",
    "            den = dictionary[current_class][\"total_words\"] + len(dictionary[current_class].keys()) - 1  \n",
    "            # den is the total number of words of a given class and the other additive part is the lapalace correction\n",
    "            current_prob = np.log(num) - np.log(den)\n",
    "        class_prob += current_prob\n",
    "    return class_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_point(x, dictionary):\n",
    "    best_prob = -1000 # this will store the best probaility among all the different classes available with us\n",
    "    best_class = -1 # this will store the class with maximum probability\n",
    "    first_run = True \n",
    "    for current_class in dictionary.keys():\n",
    "        if current_class == \"total_doc\": # if the key is \"total_doc\" we will ignore it\n",
    "            continue\n",
    "        p_curr_class = prob(dictionary, x, current_class) # calling on the prob() function to get the probability of \n",
    "                                                          # the current data point belonging to current_class\n",
    "        if (first_run or p_curr_class > best_prob):\n",
    "            best_prob = p_curr_class\n",
    "            best_class = current_class\n",
    "        first_run = False\n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_test, dictionary):\n",
    "    y_pred = [] # this list will store all the predictions of the test data\n",
    "    for x in x_test:\n",
    "        current_pred = predict_single_point(x, dictionary) \n",
    "        y_pred.append(current_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = fit(x_train,y_train) # fitting the training the data\n",
    "y_pred = predict(x_test, dictionary) # getting the corresponding predicitions of the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLASSIFICATION REPORT OF x_train AND x_test USING THE SELF-MADE MULTINOMIAL NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.95      0.95      0.95        73\n",
      "           comp.graphics       0.90      0.93      0.91        74\n",
      " comp.os.ms-windows.misc       0.85      1.00      0.92        78\n",
      "comp.sys.ibm.pc.hardware       0.92      1.00      0.96        71\n",
      "   comp.sys.mac.hardware       0.96      0.99      0.97        74\n",
      "          comp.windows.x       1.00      0.62      0.77        66\n",
      "            misc.forsale       0.91      1.00      0.95        84\n",
      "               rec.autos       0.96      1.00      0.98        72\n",
      "         rec.motorcycles       0.97      1.00      0.99        78\n",
      "      rec.sport.baseball       1.00      1.00      1.00        72\n",
      "        rec.sport.hockey       1.00      1.00      1.00        80\n",
      "               sci.crypt       1.00      0.99      0.99        80\n",
      "         sci.electronics       1.00      0.86      0.93        74\n",
      "                 sci.med       0.99      1.00      0.99        74\n",
      "               sci.space       1.00      0.97      0.99        76\n",
      "  soc.religion.christian       1.00      0.99      0.99        75\n",
      "      talk.politics.guns       0.93      1.00      0.96        78\n",
      "   talk.politics.mideast       0.99      1.00      0.99        67\n",
      "      talk.politics.misc       0.96      0.93      0.94        73\n",
      "      talk.religion.misc       0.95      0.89      0.92        81\n",
      "\n",
      "                accuracy                           0.96      1500\n",
      "               macro avg       0.96      0.96      0.96      1500\n",
      "            weighted avg       0.96      0.96      0.96      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_tr_pred=predict(x_train, dictionary) \n",
    "print(classification_report(y_train,y_tr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.77      0.63      0.69        27\n",
      "           comp.graphics       0.54      0.81      0.65        26\n",
      " comp.os.ms-windows.misc       0.64      0.73      0.68        22\n",
      "comp.sys.ibm.pc.hardware       0.78      0.97      0.86        29\n",
      "   comp.sys.mac.hardware       0.92      0.85      0.88        26\n",
      "          comp.windows.x       0.78      0.21      0.33        34\n",
      "            misc.forsale       0.56      0.88      0.68        16\n",
      "               rec.autos       0.76      0.89      0.82        28\n",
      "         rec.motorcycles       0.85      1.00      0.92        22\n",
      "      rec.sport.baseball       0.87      0.96      0.92        28\n",
      "        rec.sport.hockey       1.00      0.90      0.95        20\n",
      "               sci.crypt       0.90      0.95      0.93        20\n",
      "         sci.electronics       1.00      0.62      0.76        26\n",
      "                 sci.med       0.96      0.92      0.94        26\n",
      "               sci.space       1.00      0.83      0.91        24\n",
      "  soc.religion.christian       0.89      1.00      0.94        25\n",
      "      talk.politics.guns       0.63      0.86      0.73        22\n",
      "   talk.politics.mideast       1.00      0.88      0.94        33\n",
      "      talk.politics.misc       0.68      0.70      0.69        27\n",
      "      talk.religion.misc       0.47      0.37      0.41        19\n",
      "\n",
      "                accuracy                           0.79       500\n",
      "               macro avg       0.80      0.80      0.78       500\n",
      "            weighted avg       0.81      0.79      0.78       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCLUSIONS :\n",
    "### PRECISION ON TEST DATA:\n",
    "### USING INBUILT MULTINOMIAL NB = 0.80\n",
    "### USING SELF-MADE MULTINOMIAL NB = 0.83\n",
    " \n",
    "### PLEASE NOTE THE PRECISION MAY VARY AT THE TIME YOU VIEW IT DUE TO CERATAIN RANDOM BEHAVIOUS train_test_split INSTANCE METHOD OF THE MODEL_SELECTION LIBRARY\n",
    "\n",
    "### THIS CAN BE FURTHER IMPROVED USING NATURAL LANGUAGE PROCESSIONG. BUT USING NAIVE BAYES PROBABILITY CONCEPT THIS THE BEST PRECISION WE CAN GET."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
